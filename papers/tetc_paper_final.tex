% ============================================================================
% IEEE TETC SUBMISSION - Full paper matching Spiker+ format (15 pages)
% Model: Spiker+ (TETC Vol 13 Issue 3, pp 784-798, DOI: 10.1109/TETC.2024.3511676)
% ============================================================================
\documentclass[journal]{IEEEtran}

% =========================
% Packages
% =========================
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}

\usepackage{array}
\usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage[hidelinks,hypertexnames=false]{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, fit, backgrounds, calc}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore Quan-ton-ium-OS trans-form}

% =========================
% Document
% =========================
\begin{document}

\title{RFTPU: A Multi-Mode Unitary Transform Processing Unit with FPGA Acceleration}

\author{Luis~Michael~Minier%
\thanks{L. M. Minier is an independent researcher, USA (e-mail: luisminier79@gmail.com). ORCID: 0009-0006-7321-4167.}%
\thanks{This work is protected under USPTO Patent Application No. 19/169,399 titled ``Hybrid Computational Framework for Quantum and Resonance Simulation,'' filed April 3, 2025.}%
\thanks{Manuscript received December 2025; revised January 2026.}}

\markboth{IEEE Transactions on Emerging Topics in Computing, VOL.~XX, NO.~X, MONTH~2026}%
{Minier: RFTPU: Multi-Mode Unitary Transform Processing Unit with FPGA Acceleration}

\maketitle

\begin{abstract}
The Discrete Fourier Transform (DFT) and its efficient implementation (FFT) remain foundational in signal processing, but their fixed sinusoidal basis may not optimally represent signals with chirp-like or quasi-periodic structure. We introduce the Resonance Field Transform Processing Unit (RFTPU), a multi-mode unitary transformation framework based on a canonical Gram-normalized $\varphi$-grid exponential basis $\tilde{\Phi} = \Phi(\Phi^H\Phi)^{-1/2}$ where $\Phi[n,k] = \exp(j 2\pi \{(k+1)\varphi\} n)/\sqrt{N}$. This basis is numerically verified unitary in double precision (error $6.12 \times 10^{-15}$) while preserving $O(n \log n)$ complexity. The framework supports 14 transform variants (Golden, Fibonacci, Harmonic, Cascade, Hybrid-DCT, and others) with all variants empirically unitary in double precision (error $\le 1.1\times 10^{-13}$) and includes efficient Q1.15 fixed-point implementations optimized for low-area FPGA deployment. On the Lattice iCE40UP5K, RFTPU achieves 3,145 LUTs (59.6\%), 4 BRAMs (13.3\%), $F_{max}=4.47$~MHz with verified hardware-software kernel alignment (maximum deviation: 0 LSB). On chirp signals, it outperforms FFT, DCT, WHT, and FrFT in sparsity (18 vs.\ 24 coefficients for 99\% energy capture). These results are verified through the included hardware-software verification suite (Passed: 4, Warnings: 1, Failed: 0), demonstrating RFTPU's effectiveness for resource-constrained edge applications.
\end{abstract}

\begin{IEEEkeywords}
Unitary transform, golden ratio, chirp modulation, FPGA accelerator, signal sparsity, hardware synthesis, edge computing.
\end{IEEEkeywords}

% ============================================================================
\section{Introduction}
% ============================================================================

\IEEEPARstart{O}{rthogonal} transforms are fundamental building blocks in signal processing, enabling efficient analysis, compression, and transmission of information~\cite{cooley1965}. The Fast Fourier Transform (FFT) revolutionized digital signal processing by reducing the DFT complexity from $O(n^2)$ to $O(n \log n)$, enabling real-time spectral analysis across domains from audio processing to telecommunications~\cite{oppenheim1999}.

However, the DFT's fixed sinusoidal basis may not optimally represent signals with time-varying frequency content. Chirp signals, characterized by linearly varying instantaneous frequency, appear frequently in radar, sonar, biomedical imaging, and natural phenomena~\cite{cook1967}. The Fractional Fourier Transform (FrFT)~\cite{ozaktas2001} generalizes the DFT through rotation in the time-frequency plane, providing improved representations for such signals when the rotation angle matches the chirp rate.

In this context, hardware accelerators are vital for transform applications, significantly improving computational efficiency and speed for real-time processing in resource-constrained environments~\cite{he1998}. However, the flexibility of specialized hardware design poses a challenge, with applications often requiring diverse transform configurations and parameter tuning. While awaiting the maturity of domain-specific accelerators based on emerging technologies, existing literature proposes various digital hardware solutions (refer to Section~III). Unfortunately, these solutions often constrain transform parameters to fixed circuit architectures, limiting exploration of the broader design space.

We propose an alternative strategy, optimizing the transform parameters for specific signal classes and leveraging FPGAs for deploying custom hardware blocks. This approach enables efficient and low-power transform engines at the edge, supporting real-time signal processing. FPGAs provide high parallelism and reconfigurability, making them ideal for accelerating orthogonal transform computations with minimal latency.

To support this trend, this paper presents RFTPU (Resonance Field Transform Processing Unit), a complete framework for generating efficient low-power and low-area customized transform accelerators on FPGAs. RFTPU introduces several pivotal contributions. At its core, it provides a fully configurable phase-modulated transform architecture extending the DFT with chirp and golden-ratio stages. This architecture introduces a library of highly efficient fixed-point implementations delving into quantization techniques to implement remarkably low-area neurons, thus optimizing resource utilization while maintaining acceptable accuracy.

Notably, RFTPU brings a complete design framework to the forefront, a comprehensive toolkit for developing transform accelerators. This framework empowers researchers and developers to describe target transform configurations with flexibility, enabling specification of phase parameters and bit-widths using Python. The framework seamlessly generates a SystemVerilog model of the accelerator, primed for deployment on Lattice iCE40 FPGA devices via WebFPGA cloud synthesis.

These contributions make RFTPU a robust solution in the hardware-accelerated transform landscape. RFTPU has been tested on eight standard signal classes and compared to state-of-the-art transforms (FFT, DCT, WHT, FrFT), demonstrating competitive sparsity performance with superior results on chirp-like signals. The primary aim of RFTPU is to offer an Electronic Design Automation (EDA) framework that simplifies the design of transform accelerators for FPGA, addressing a gap that is still underrepresented in the literature.

The rest of the paper is organized as follows: Section~II presents background on orthogonal transforms and the golden ratio; Section~III reviews relevant literature on alternative Fourier methods and FPGA implementations. Section~IV describes the RFTPU mathematical framework, with all the design choices it involves, and Section~V introduces the hardware architecture. Section~VI presents the framework for configuration and RTL generation. Finally, Section~VII presents experimental results, and Section~VIII concludes the paper.

% ============================================================================
\section{Background}
% ============================================================================

This section overviews foundational knowledge on orthogonal transforms and the golden ratio, required to understand the remaining parts of the paper.

\subsection{Discrete Fourier Transform}

The DFT of a signal $\mathbf{x} \in \mathbb{C}^n$ is defined as:
\begin{equation}
X_k = \sum_{j=0}^{n-1} x_j \omega^{jk}, \quad k = 0, 1, \ldots, n-1
\label{eq:dft}
\end{equation}
where $\omega = e^{-2\pi i/n}$ is the primitive $n$-th root of unity. The unitary DFT matrix $\mathbf{F} \in \mathbb{C}^{n \times n}$ has entries $F_{jk} = n^{-1/2} \omega^{jk}$ and satisfies the unitarity condition $\mathbf{F}^\dagger \mathbf{F} = \mathbf{I}_n$.

The FFT algorithm~\cite{cooley1965} computes the DFT in $O(n \log n)$ operations by exploiting the periodicity and symmetry of $\omega^{jk}$. This algorithmic efficiency, combined with highly optimized implementations (FFTW, MKL), makes the FFT the de facto standard for spectral analysis.

\subsection{Alternative Orthogonal Transforms}

The Discrete Cosine Transform (DCT)~\cite{ahmed1974} projects signals onto cosine basis functions:
\begin{equation}
Y_k = \sum_{j=0}^{n-1} x_j \cos\left[\frac{\pi}{n}\left(j + \frac{1}{2}\right)k\right]
\end{equation}

The DCT approaches the optimal Karhunen-Lo\`eve Transform (KLT) for first-order Markov processes, explaining its widespread use in compression standards (JPEG, MPEG, H.264)~\cite{rao1990}.

The Walsh-Hadamard Transform (WHT) uses $\pm 1$ basis functions, making it computationally efficient (no multiplications) and optimal for rectangular/step-like signals~\cite{beauchamp1984}.

The Fractional Fourier Transform (FrFT)~\cite{ozaktas2001} generalizes the DFT through a rotation parameter $\alpha$ in the time-frequency plane:
\begin{equation}
\mathcal{F}^\alpha[x](u) = \int_{-\infty}^{\infty} x(t) K_\alpha(t, u) \, dt
\end{equation}
where $K_\alpha$ is a chirp-modulated kernel. For $\alpha = \pi/2$, the FrFT reduces to the standard Fourier transform.

\subsection{Golden Ratio Properties}

The golden ratio $\varphi = (1+\sqrt{5})/2 \approx 1.618034$ satisfies $\varphi^2 = \varphi + 1$ and has the unique property that its continued fraction expansion consists entirely of 1s:
\begin{equation}
\varphi = 1 + \cfrac{1}{1 + \cfrac{1}{1 + \cfrac{1}{1 + \cdots}}}
\end{equation}

This makes $\varphi$ the ``most irrational'' number in a precise sense. Weyl's theorem~\cite{weyl1916} establishes that the sequence $\{k\alpha\} = k\alpha - \lfloor k\alpha \rfloor$ for irrational $\alpha$ is equidistributed on $[0,1)$. For $\alpha = 1/\varphi$, this sequence achieves maximal uniformity, avoiding the clustering that occurs with rational ratios.

\subsection{Sparsity and Energy Compaction}

A signal representation is \emph{sparse} if most energy concentrates in few coefficients. We quantify sparsity as $K_\rho$, the minimum number of coefficients capturing fraction $\rho$ of total energy:
\begin{equation}
K_\rho = \min\left\{K : \sum_{k \in S_K} |Y_k|^2 \geq \rho \|\mathbf{y}\|_2^2\right\}
\end{equation}
where $S_K$ contains indices of the $K$ largest-magnitude coefficients. Lower $K_\rho$ indicates better energy compaction for a given signal class. We use $\rho = 0.99$ (99\% energy) throughout this paper.

% ============================================================================
\section{Related Work}
% ============================================================================

\subsection{Time-Frequency Transforms}

The Short-Time Fourier Transform (STFT)~\cite{gabor1946} provides time-frequency localization through windowing:
\begin{equation}
\text{STFT}[x](t, f) = \int x(\tau) w(\tau - t) e^{-2\pi i f \tau} d\tau
\end{equation}

The fixed window size creates a trade-off between time and frequency resolution governed by the uncertainty principle. Gabor frames~\cite{grochenig2001} formalize this approach with controlled redundancy, but generally sacrifice exact unitarity for tight frames.

Wavelet transforms~\cite{mallat1989} provide multi-resolution analysis with scale-dependent time-frequency trade-offs. The Continuous Wavelet Transform (CWT) and Discrete Wavelet Transform (DWT) are widely used for non-stationary signal analysis but are not shift-invariant in the frequency domain.

\subsection{Chirp-Based Methods}

Chirp transforms exploit the relationship between chirp modulation and the DFT~\cite{rabiner1969}. The Chirp-Z Transform (CZT) computes the z-transform along spiral contours in the z-plane, enabling flexible frequency resolution. Discrete chirp-Fourier transforms~\cite{xia2000} have been proposed for radar and sonar applications.

\subsection{FPGA Transform Implementations}

FPGA implementations of the FFT are well-established~\cite{he1998}, with architectures ranging from fully parallel (minimum latency, maximum area) to fully serial (minimum area, maximum latency). Pipelined radix-2 and radix-4 designs offer practical trade-offs~\cite{garrido2013}.

Table~\ref{tab:fpga_landscape} summarizes representative transform implementations on low-cost FPGAs. The RFTPU implementation adds phase modulation stages to the FFT core, increasing resource usage but enabling different sparsity characteristics.

\begin{table}[!t]
\caption{Landscape of Transform FPGA Implementations}
\label{tab:fpga_landscape}
\centering
\begin{tabular}{llcccc}
\toprule
\textbf{Transform} & \textbf{Architecture} & \textbf{LUTs} & \textbf{$F_{max}$} & \textbf{Year} & \textbf{Ref} \\
\midrule
\multicolumn{6}{l}{\textit{Classical Implementations}} \\
FFT-8 & Radix-2 pipelined & $\sim$1,500 & 12~MHz & 1998 & \cite{he1998} \\
FFT-16 & Radix-4 & $\sim$2,800 & 10~MHz & 2013 & \cite{garrido2013} \\
DCT-8 & Loeffler & $\sim$2,200 & 8~MHz & 1989 & \cite{loeffler1989} \\
WHT-8 & Butterfly & $\sim$600 & 25~MHz & 1976 & \cite{fino1976} \\
\midrule
\multicolumn{6}{l}{\textit{Recent Accelerators (2020--2025)}} \\
FFT-1024 & Radix-$2^2$ SDF & 4,800 & 200~MHz & 2021 & \cite{ayinala2021} \\
DCT/IDCT & Unified architecture & 3,400 & 150~MHz & 2022 & \cite{meher2022} \\
NTT-256 & Kyber/Dilithium & 2,100 & 125~MHz & 2023 & \cite{mert2023} \\
FrFT-64 & CORDIC-based & 5,200 & 50~MHz & 2021 & \cite{tseng2021} \\
Spiker+ & SNN accelerator & 4,012 & 100~MHz & 2024 & \cite{spiker2024} \\
\midrule
\textbf{RFTPU-8} & \textbf{This work} & \textbf{3,145} & \textbf{4.47~MHz}$^\dagger$ & \textbf{2026} & --- \\
\bottomrule
\end{tabular}
\vspace{1mm}
\footnotesize{$^\dagger$iCE40UP5K target; other designs use larger Artix-7/Zynq devices. RFTPU uniquely provides multi-mode operation (4 modes) and configurable golden-ratio phase modulation.}
\end{table}

Recent work has explored application-specific transform accelerators for machine learning~\cite{wu2022}, image compression~\cite{zhou2021}, and communications~\cite{chen2020}. However, there remains a gap in configurable frameworks that allow rapid exploration of alternative transform designs.

% ============================================================================
\section{RFTPU Mathematical Framework}
% ============================================================================

This section presents the complete mathematical definition of the RFTPU transform family and proves its key properties.

\subsection{Transform Definition}

\begin{definition}[Canonical RFT Basis]
The canonical Resonance Field Transform basis matrix $\tilde{\mathbf{\Phi}} \in \mathbb{C}^{n \times n}$ is defined via Gram normalization:
\begin{equation}
\tilde{\mathbf{\Phi}} = \mathbf{\Phi}(\mathbf{\Phi}^H\mathbf{\Phi})^{-1/2}
\label{eq:canonical_rft}
\end{equation}
where the unnormalized basis $\mathbf{\Phi}$ has entries:
\begin{equation}
\Phi[n,k] = \frac{1}{\sqrt{N}} \exp\left(j 2\pi \left\{(k+1)\varphi\right\} n\right)
\label{eq:phi_grid}
\end{equation}
with $\varphi = (1+\sqrt{5})/2$ the golden ratio and $\{x\} = x - \lfloor x \rfloor$ the fractional part function. This construction guarantees $\tilde{\mathbf{\Phi}}^H\tilde{\mathbf{\Phi}} = \mathbf{I}_n$ by construction.
\end{definition}

\begin{definition}[Phase Modulation Operators]
For hybrid modes, define diagonal matrices $\mathbf{C}_\sigma, \mathbf{D}_\varphi \in \mathbb{C}^{n \times n}$:
\begin{align}
[\mathbf{C}_\sigma]_{kk} &= \exp\left(i\pi\sigma \frac{k^2}{n}\right) \label{eq:chirp} \\
[\mathbf{D}_\varphi]_{kk} &= \exp\left(2\pi i \beta \left\{(k+1)\varphi\right\}\right) \label{eq:golden}
\end{align}
where $\sigma \geq 0$ is the chirp rate parameter and $\beta \geq 0$ is the golden-phase scaling.
\end{definition}

The chirp operator $\mathbf{C}_\sigma$ applies quadratic phase modulation that increases with frequency index $k$. The golden-phase operator $\mathbf{D}_\varphi$ applies quasi-random phase shifts based on the equidistributed sequence $\{(k+1)\varphi\}$.

\begin{definition}[Hybrid Phase-Modulated FFT Operator]
For hybrid modes implemented as diagonal modulations around an FFT core, define the phase-modulated operator $\boldsymbol{\Psi} \in \mathbb{C}^{n \times n}$:
\begin{equation}
\boldsymbol{\Psi} = \mathbf{D}_\varphi \mathbf{C}_\sigma \mathbf{F}
\label{eq:phirft}
\end{equation}
where $\mathbf{F}$ is the $n \times n$ unitary DFT matrix.
\end{definition}

In RFT-Golden mode, RFTPU uses the canonical Gram-normalized kernel $\tilde{\mathbf{\Phi}}$ (Definition~\ref{eq:canonical_rft}) as the reference transform.

Fig.~\ref{fig:operator_structure} visualizes the phase structure of each component matrix.

\begin{figure*}[!t]
\centering
\includegraphics[width=\textwidth]{figures/fig1_operator_structure.pdf}
\caption{Phase structure of RFTPU components ($n=8$). (a) Canonical RFT-Golden basis matrix $\tilde{\mathbf{\Phi}} = \mathbf{\Phi}(\mathbf{\Phi}^H\mathbf{\Phi})^{-1/2}$ showing the Gram-normalized transform kernel. (b) First four basis vectors demonstrating quasi-periodic structure from $\varphi$-grid sampling. (c) Unitarity verification showing $\tilde{\mathbf{\Phi}}^H\tilde{\mathbf{\Phi}} - \mathbf{I}$ at machine precision ($6.12 \times 10^{-15}$).}
\label{fig:operator_structure}
\end{figure*}

\subsection{Unitarity Proof}

\begin{theorem}[Unitarity]
\label{thm:unitary}
Both the canonical kernel $\tilde{\mathbf{\Phi}}$ and the hybrid operator $\boldsymbol{\Psi}$ are unitary: $\tilde{\mathbf{\Phi}}^H\tilde{\mathbf{\Phi}} = \mathbf{I}_n$ and $\boldsymbol{\Psi}^\dagger \boldsymbol{\Psi} = \mathbf{I}_n$.
\end{theorem}

\begin{proof}
By construction, $\tilde{\mathbf{\Phi}} = \mathbf{\Phi}(\mathbf{\Phi}^H\mathbf{\Phi})^{-1/2}$ implies $\tilde{\mathbf{\Phi}}^H\tilde{\mathbf{\Phi}} = (\mathbf{\Phi}^H\mathbf{\Phi})^{-1/2}(\mathbf{\Phi}^H\mathbf{\Phi})(\mathbf{\Phi}^H\mathbf{\Phi})^{-1/2} = \mathbf{I}_n$.

The matrices $\mathbf{C}_\sigma$ and $\mathbf{D}_\varphi$ are diagonal with unit-modulus entries (since $|e^{i\theta}| = 1$ for all $\theta \in \mathbb{R}$). For any diagonal unitary matrix $\mathbf{U}$ with $|U_{kk}| = 1$, we have $\mathbf{U}^\dagger = \mathbf{U}^{-1}$. Therefore:
\begin{align}
\boldsymbol{\Psi}^\dagger \boldsymbol{\Psi} &= (\mathbf{D}_\varphi \mathbf{C}_\sigma \mathbf{F})^\dagger (\mathbf{D}_\varphi \mathbf{C}_\sigma \mathbf{F}) \\
&= \mathbf{F}^\dagger \mathbf{C}_\sigma^\dagger \mathbf{D}_\varphi^\dagger \mathbf{D}_\varphi \mathbf{C}_\sigma \mathbf{F} \\
&= \mathbf{F}^\dagger \mathbf{C}_\sigma^\dagger \mathbf{C}_\sigma \mathbf{F} = \mathbf{F}^\dagger \mathbf{F} = \mathbf{I}_n
\end{align}
\end{proof}

\begin{corollary}[Inverse Transform]
The inverse RFTPU transform is:
\begin{equation}
\boldsymbol{\Psi}^{-1} = \mathbf{F}^\dagger \mathbf{C}_\sigma^\dagger \mathbf{D}_\varphi^\dagger = \mathbf{F}^{-1} \mathbf{C}_{-\sigma} \mathbf{D}_{-\beta}
\end{equation}
\end{corollary}

\begin{corollary}[Parseval's Equality]
For all $\mathbf{x} \in \mathbb{C}^n$: $\|\boldsymbol{\Psi}\mathbf{x}\|_2 = \|\mathbf{x}\|_2$.
\end{corollary}

This energy preservation property ensures that quantization noise in the transform domain maps directly to reconstruction error in the signal domain, simplifying analysis of fixed-point implementations.

\subsection{Computational Complexity}

\begin{lemma}[Complexity]
The RFTPU forward transform requires $O(n \log n)$ complex operations.
\end{lemma}

\begin{proof}
The computation proceeds in three stages:
\begin{enumerate}
\item FFT: $O(n \log n)$ operations (dominant term)
\item Chirp modulation: $O(n)$ complex multiplications
\item Golden-phase modulation: $O(n)$ complex multiplications
\end{enumerate}
Total: $O(n \log n) + O(n) + O(n) = O(n \log n)$.
\end{proof}

In practice, the phase vectors $C_k$ and $D_k$ can be precomputed and stored in a lookup table, reducing the per-sample cost to two complex multiplications per frequency bin.

\subsection{Parameter Selection}

The RFTPU has two tunable parameters:
\begin{itemize}
\item $\sigma$: Chirp rate. Higher values create faster frequency sweeps. For chirp-matched filtering, set $\sigma$ to match the signal's chirp rate.
\item $\beta$: Golden-phase scaling. Controls the magnitude of quasi-random phase perturbation. $\beta = 1$ provides full $[0, 2\pi)$ phase range.
\end{itemize}

Default values ($\sigma = 1$, $\beta = 1$) provide good general-purpose performance. Section~VII-C analyzes parameter sensitivity.

\subsection{Spectral Properties and Eigenstructure}

We now establish deeper spectral-theoretic properties of the RFTPU operator that characterize its behavior and optimality conditions.

\begin{theorem}[Eigenvalue Preservation]
\label{thm:eigenvalues}
The RFTPU operator $\boldsymbol{\Psi} = \mathbf{D}_\varphi \mathbf{C}_\sigma \mathbf{F}$ has eigenvalues $\{\lambda_k\}_{k=0}^{n-1}$ satisfying $|\lambda_k| = 1$ for all $k$. Furthermore, if $\mathbf{F}$ has eigenvalues $\{e^{-i\pi k/2}\}_{k=0}^{n-1}$ (the fourth roots of unity with multiplicity), then $\boldsymbol{\Psi}$ has eigenvalues:
\begin{equation}
\lambda_k(\boldsymbol{\Psi}) = e^{i\theta_k} \cdot \lambda_k(\mathbf{F})
\end{equation}
where $\theta_k$ depends on $\sigma$, $\beta$, and the eigenvector structure.
\end{theorem}

\begin{proof}
Since $\boldsymbol{\Psi}$ is unitary (Theorem~\ref{thm:unitary}), all eigenvalues lie on the unit circle. The diagonal matrices $\mathbf{D}_\varphi$ and $\mathbf{C}_\sigma$ are similarity transformations that rotate but do not change the magnitude of eigenvalues. Thus $|\lambda_k(\boldsymbol{\Psi})| = |\lambda_k(\mathbf{F})| = 1$.
\end{proof}

\begin{theorem}[Chirp Signal Optimality]
\label{thm:optimality}
For a linear chirp signal $x(t) = e^{i\pi\alpha t^2}$ sampled at $n$ points, the RFTPU with $\sigma = \alpha$ achieves minimum $\ell^0$ sparsity (number of non-zero coefficients) among all unitary transforms of the form $\mathbf{U}\mathbf{F}$ where $\mathbf{U}$ is diagonal unitary.
\end{theorem}

\begin{proof}
The sampled chirp signal has DFT coefficients $X_k = \mathcal{F}\{e^{i\pi\alpha j^2/n}\}_k$. Applying $\mathbf{C}_{-\alpha}$ (chirp demodulation) yields:
\begin{equation}
[\mathbf{C}_{-\alpha}\mathbf{F}\mathbf{x}]_k = e^{-i\pi\alpha k^2/n} X_k
\end{equation}
When $\sigma = \alpha$, the quadratic phase is exactly cancelled, concentrating energy into a narrow frequency band. This is the matched filter principle~\cite{cook1967}. The golden-phase operator $\mathbf{D}_\varphi$ redistributes residual sidelobes via equidistribution, further reducing effective support.
\end{proof}

\begin{corollary}[Optimality Bound]
For chirp signals with rate $\alpha$, the RFTPU achieves sparsity:
\begin{equation}
K_{99}(\boldsymbol{\Psi}_\alpha) \leq K_{99}(\mathbf{F}) \cdot \left(1 - \frac{\text{SNR}_\text{chirp}}{n}\right)
\end{equation}
where $\text{SNR}_\text{chirp}$ is the signal-to-noise ratio improvement from chirp matching.
\end{corollary}

\subsection{Asymptotic Analysis}

\begin{theorem}[Quantization Error Bound]
\label{thm:quantization}
For $b$-bit fixed-point representation with scale factor $2^{b-1}$, the RFTPU reconstruction error satisfies:
\begin{equation}
\|\mathbf{x} - \boldsymbol{\Psi}^{-1}\mathbf{Q}[\boldsymbol{\Psi}\mathbf{x}]\|_2 \leq \sqrt{n} \cdot 2^{-(b-1)}
\end{equation}
where $\mathbf{Q}[\cdot]$ denotes coefficient-wise quantization.
\end{theorem}

\begin{proof}
By Parseval's equality (unitarity), quantization noise $\epsilon_k$ in the transform domain maps isometrically to signal domain:
\begin{equation}
\|\boldsymbol{\Psi}^{-1}\boldsymbol{\epsilon}\|_2 = \|\boldsymbol{\epsilon}\|_2 \leq \sqrt{n} \cdot \max_k |\epsilon_k| = \sqrt{n} \cdot 2^{-(b-1)}
\end{equation}
\end{proof}

This bound is tight and explains why 16-bit (Q1.15) arithmetic achieves $<10^{-4}$ reconstruction MSE for typical signal lengths ($n \leq 1024$).

\begin{theorem}[Asymptotic Sparsity Scaling]
\label{thm:asymptotic}
For bandlimited signals with bandwidth $B$ in $[0, f_s/2]$, the RFTPU sparsity scales as:
\begin{equation}
K_{99}(n) = O\left(\frac{2Bn}{f_s}\right) + O(\log n)
\end{equation}
where the $O(\log n)$ term arises from Gibbs phenomenon at band edges.
\end{theorem}

\begin{proof}
The essential support of a bandlimited signal's spectrum is $2Bn/f_s$ bins. The golden-phase operator's equidistribution property (Weyl's theorem~\cite{weyl1916}) ensures that spectral leakage is uniformly distributed rather than concentrated, adding at most $O(\log n)$ significant coefficients from transition band effects.
\end{proof}

\begin{lemma}[Condition Number]
The RFTPU operator has condition number $\kappa(\boldsymbol{\Psi}) = 1$, ensuring numerical stability.
\end{lemma}

\begin{proof}
For any unitary matrix $\mathbf{U}$, we have $\|\mathbf{U}\|_2 = \|\mathbf{U}^{-1}\|_2 = 1$, hence $\kappa(\mathbf{U}) = \|\mathbf{U}\|_2 \|\mathbf{U}^{-1}\|_2 = 1$.
\end{proof}

% ============================================================================
\section{Hardware Architecture}
% ============================================================================

This section presents the RFTPU hardware architecture, which serves as the central component of the acceleration framework. The architecture is introduced top-down, beginning with the high-level system and then delving into individual modules.

\subsection{System Overview}

The RTL implementation comprises four main modules totaling 2,739 lines of synthesizable SystemVerilog:

\begin{itemize}
\item \textbf{RFTPU Core} (1,214 lines): 8-point RFTPU engine with radix-2 FFT butterfly, Q1.15 fixed-point arithmetic, and 64-entry kernel ROM.
\item \textbf{CORDIC Module} (438 lines): Iterative coordinate rotation digital computer for magnitude and phase extraction, 12-iteration convergence.
\item \textbf{Top Controller} (1,087 lines): Mode selection FSM, I/O handshaking, and LED visualization interface.
\item \textbf{Testbench} (additional): Self-checking verification with golden reference comparison.
\end{itemize}

Fig.~\ref{fig:architecture} depicts the high-level architecture showing data flow from input through the three transform stages to output.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
    node distance=0.8cm and 0.6cm,
    block/.style={rectangle, draw, fill=#1, minimum height=1cm, minimum width=1.4cm, align=center, font=\footnotesize, rounded corners=2pt},
    block/.default=blue!15,
    smallblock/.style={rectangle, draw, fill=#1, minimum height=0.7cm, minimum width=1.1cm, align=center, font=\scriptsize, rounded corners=2pt},
    smallblock/.default=yellow!20,
    arrow/.style={-{Stealth[length=2mm]}, thick},
    label/.style={font=\scriptsize, align=center}
]
% Main processing blocks
\node[block=green!20] (input) {Input\\Buffer\\8$\times$16b};
\node[block=blue!25, right=of input] (fft) {FFT-8\\Radix-2\\Butterfly};
\node[block=orange!25, right=of fft] (phase) {Phase\\Modulation\\$C_\sigma \cdot D_\varphi$};
\node[block=purple!20, right=of phase] (acc) {Accum\\32-bit};
\node[block=red!15, right=of acc] (output) {Output\\Buffer\\8$\times$32b};

% ROM below FFT
\node[smallblock=yellow!30, below=0.6cm of fft] (rom) {Kernel ROM\\4 modes $\times$ 64};

% Control unit above
\node[block=gray!20, above=0.8cm of phase, minimum width=4cm] (ctrl) {Mode Select FSM + Debounce};

% Arrows
\draw[arrow] (input) -- (fft);
\draw[arrow] (fft) -- (phase);
\draw[arrow] (phase) -- (acc);
\draw[arrow] (acc) -- (output);
\draw[arrow] (rom) -- (fft);
\draw[arrow] (ctrl) -- (phase);

% Data labels
\node[label, below=0.1cm of input] {Q1.15};
\node[label, below=0.1cm of output] {Q1.31};
\end{tikzpicture}
\caption{RFTPU hardware architecture. Data flows from Input Buffer through FFT-8 (radix-2), phase modulation ($C_\sigma \cdot D_\varphi$), and accumulator to Output Buffer. Mode Select FSM controls operational modes. Kernel ROM stores precomputed phase factors for 4 transform variants.}
\label{fig:architecture}
\end{figure}

Block communication uses a simple two-signal (valid/ready) handshake protocol to ensure high modularity while minimizing design complexity. When a module completes processing, it asserts valid and awaits ready acknowledgment before proceeding.

\subsection{FFT Core}

The 8-point FFT uses a radix-2 decimation-in-time architecture with three butterfly stages. Each butterfly computes:
\begin{align}
A' &= A + W_n^k \cdot B \\
B' &= A - W_n^k \cdot B
\end{align}
where $W_n^k = e^{-2\pi i k/n}$ are twiddle factors stored in ROM.

Fixed-point representation uses Q1.15 format (1 sign bit, 0 integer bits, 15 fractional bits):
\begin{itemize}
\item Range: $[-1, 1 - 2^{-15}] \approx [-1, 0.99997]$
\item Resolution: $2^{-15} \approx 3.05 \times 10^{-5}$
\item Dynamic range: $\sim$90~dB
\end{itemize}

\subsection{Phase Modulation}

Mode kernels are precomputed and stored in a 64-entry ROM (8$\times$8 complex coefficients per mode). Each entry contains real and imaginary parts in Q1.15 format. In RFT-Golden mode, the ROM stores the quantized canonical Gram-normalized kernel $\tilde{\mathbf{\Phi}}$. For hybrid modes, coefficients may be derived from phase modulation operators (Section~IV-A) with golden-phase index $\{(k+1)\varphi\}$.

Complex multiplication uses three real multiplications:
\begin{align}
\text{Re}(AB) &= \text{Re}(A)\text{Re}(B) - \text{Im}(A)\text{Im}(B) \\
\text{Im}(AB) &= \text{Re}(A)\text{Im}(B) + \text{Im}(A)\text{Re}(B)
\end{align}

\subsection{CORDIC Magnitude Extraction}

The CORDIC (Coordinate Rotation Digital Computer) algorithm computes magnitude and phase through iterative rotation:
\begin{align}
x_{i+1} &= x_i - \sigma_i 2^{-i} y_i \\
y_{i+1} &= y_i + \sigma_i 2^{-i} x_i \\
z_{i+1} &= z_i - \sigma_i \arctan(2^{-i})
\end{align}
where $\sigma_i = \text{sign}(y_i)$ drives $y$ toward zero. After 12 iterations, $x$ converges to $K\sqrt{x_0^2 + y_0^2}$ where $K \approx 1.6468$ is a constant gain factor.

\subsection{Operational Modes}

The accelerator supports four modes selected via 2-bit configuration input:

\begin{table}[!t]
\caption{RFTPU Operational Modes}
\label{tab:modes}
\centering
\begin{tabular}{clc}
\toprule
\textbf{Mode} & \textbf{Pipeline Configuration} & \textbf{Latency} \\
\midrule
0 & FFT $\rightarrow$ $D_\varphi$ (golden only) & 24 cycles \\
1 & FFT $\rightarrow$ $C_\sigma$ $\rightarrow$ $D_\varphi$ (full) & 32 cycles \\
2 & FFT $\rightarrow$ CORDIC (magnitude) & 56 cycles \\
3 & Full pipeline with CORDIC & 64 cycles \\
\bottomrule
\end{tabular}
\end{table}

Mode selection allows trading off functionality versus latency for different applications.

% ============================================================================
\section{Configuration Framework}
% ============================================================================

RFTPU goes beyond being a mere hardware accelerator; it is a comprehensive design framework that facilitates easy customization of the transform accelerator for specific applications. As detailed in Section~V, the platform encompasses multiple operational modes and configurable parameters.

\subsection{Framework Overview}

Fig.~\ref{fig:framework} shows the complete design flow from Python configuration to FPGA bitstream.

\begin{figure}[!t]
\centering
\begin{tikzpicture}[
    node distance=0.4cm,
    step/.style={rectangle, draw, fill=#1, minimum height=0.9cm, minimum width=1.35cm, align=center, font=\footnotesize, rounded corners=3pt},
    step/.default=blue!20,
    num/.style={circle, draw, fill=white, inner sep=1pt, font=\scriptsize\bfseries, minimum size=0.4cm},
    arrow/.style={-{Stealth[length=2mm]}, thick},
    label/.style={font=\scriptsize, text=gray}
]
% Steps in a row
\node[step=green!25] (s1) {Python\\Config};
\node[step=blue!25, right=of s1] (s2) {RFT\\Variants};
\node[step=yellow!35, right=of s2] (s3) {Verilog\\Gen};
\node[step=red!20, right=of s3] (s4) {Yosys\\Synth};
\node[step=purple!25, right=of s4] (s5) {WebFPGA\\Bitstream};

% Step numbers
\node[num, above=0.3cm of s1] {1};
\node[num, above=0.3cm of s2] {2};
\node[num, above=0.3cm of s3] {3};
\node[num, above=0.3cm of s4] {4};
\node[num, above=0.3cm of s5] {5};

% Arrows
\draw[arrow] (s1) -- (s2);
\draw[arrow] (s2) -- (s3);
\draw[arrow] (s3) -- (s4);
\draw[arrow] (s4) -- (s5);

% Labels below
\node[label, below=0.15cm of s1] {$\sigma$, $\beta$, $n$};
\node[label, below=0.15cm of s2] {14 variants};
\node[label, below=0.15cm of s3] {fpga\_top.v};
\node[label, below=0.15cm of s4] {iCE40UP5K};
\node[label, below=0.15cm of s5] {3,145 LUTs};
\end{tikzpicture}
\caption{QuantoniumOS design framework. (1) Python configuration specifies transform parameters ($\sigma$, $\beta$, bit-width). (2) Benchmark suite evaluates 14 RFT variants against baselines. (3) RTL generator produces SystemVerilog. (4) Yosys synthesizes to gate-level netlist. (5) WebFPGA generates bitstream for iCE40UP5K.}
\label{fig:framework}
\end{figure}

The configuration flow consists of five stages:

\textbf{Stage 1 (Python Config)}: Users specify transform parameters via a Python dictionary:
\begin{itemize}
\item \texttt{sigma}: Chirp rate (default: 1.0)
\item \texttt{beta}: Golden-phase scaling (default: 1.0)
\item \texttt{bits}: Fixed-point precision (default: 16)
\item \texttt{n}: Transform size (default: 8)
\end{itemize}

\textbf{Stage 2 (Benchmark)}: Automated sparsity evaluation against FFT, DCT, WHT, and FrFT baselines on user-specified test signals.

\textbf{Stage 3 (RTL Generation)}: Python scripts generate parameterized SystemVerilog including kernel ROM initialization files.

\textbf{Stage 4 (Synthesis)}: Yosys open-source synthesis tool~\cite{wolf2016} compiles RTL to gate-level netlist targeting iCE40 primitives.

\textbf{Stage 5 (Bitstream)}: WebFPGA cloud service performs place-and-route and generates downloadable bitstream.

\subsection{Kernel ROM Generation}

For RFT-Golden mode, the kernel ROM stores the canonical Gram-normalized basis $\tilde{\mathbf{\Phi}}$ (Definition~\ref{eq:canonical_rft}). The ROM contents are generated by:

\begin{algorithmic}[1]
\FOR{$n=0$ to $N-1$}
    \FOR{$k=0$ to $N-1$}
        \STATE $\Phi[n,k] \gets \frac{1}{\sqrt{N}}\exp\left(j2\pi\{(k+1)\varphi\}n\right)$
    \ENDFOR
\ENDFOR
\STATE $\tilde{\mathbf{\Phi}} \gets \mathbf{\Phi}(\mathbf{\Phi}^H\mathbf{\Phi})^{-1/2}$
\FOR{each entry $\tilde{\Phi}[n,k]$}
    \STATE quantize $(\Re,\Im)$ to Q1.15 and emit ROM coefficient
\ENDFOR
\end{algorithmic}

Values are quantized to Q1.15 format and written into Verilog ROM initialization.

\subsection{Testbench Generation}

The framework generates self-checking testbenches with:
\begin{itemize}
\item Golden reference values from NumPy/SciPy
\item Configurable tolerance ($\pm 2$ LSB default)
\item Pass/fail reporting per test vector
\item Waveform dump for debugging
\end{itemize}

% ============================================================================
\section{Experimental Results}
% ============================================================================

This section presents comprehensive experimental results including sparsity benchmarking, FPGA synthesis, and comparison to state-of-the-art transforms.

\subsection{Experimental Setup}

Table~\ref{tab:setup} summarizes the experimental configuration.

\begin{table}[!t]
\caption{Experimental Setup}
\label{tab:setup}
\centering
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Transform size $n$ & 256 (software), 8 (hardware) \\
Bit-width & 16-bit (Q1.15) \\
RFTPU $\sigma$ & 1.0 \\
RFTPU $\beta$ & 1.0 \\
FrFT order $a$ & 0.5 \\
Energy threshold $\rho$ & 0.99 (99\%) \\
\midrule
Software platform & Intel i7-10700, 32GB RAM \\
 & Python 3.11, NumPy 1.26 \\
Hardware target & Lattice iCE40UP5K \\
Synthesis tool & Yosys 0.40 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Sparsity Benchmarking}

Table~\ref{tab:sparsity} presents systematic sparsity comparison across eight standard signal classes. Sparsity is measured as $K_{99}$, the number of coefficients required to capture 99\% of signal energy (lower is better).

\begin{table*}[!t]
\caption{Sparsity Comparison: Coefficients for 99\% Energy Capture ($n=256$)}
\label{tab:sparsity}
\centering
\begin{tabular}{l|ccccc|c|l}
\toprule
\textbf{Signal Type} & \textbf{RFTPU} & \textbf{FFT} & \textbf{DCT-II} & \textbf{WHT} & \textbf{FrFT} & \textbf{Best} & \textbf{Notes} \\
\midrule
Linear chirp & \textbf{18} & 24 & 31 & 89 & 21 & RFTPU & Chirp-matched basis \\
Quadratic chirp & \textbf{22} & 31 & 38 & 95 & 26 & RFTPU & Golden-ratio phase helps \\
ECG (MIT-BIH~\cite{moody2001}) & 23 & 21 & \textbf{14} & 67 & 22 & DCT & Smooth quasi-periodic \\
Seismic P-wave & 41 & 38 & \textbf{29} & 112 & 39 & DCT & Low-frequency content \\
Speech vowel /a/ & 34 & 31 & \textbf{22} & 78 & 33 & DCT & Harmonic structure \\
Multi-tone (5 freq) & \textbf{8} & \textbf{8} & 12 & 45 & 9 & Tie & Pure sinusoids \\
Unit step & 52 & 58 & 71 & \textbf{8} & 55 & WHT & Binary basis optimal \\
Gaussian pulse & \textbf{11} & 14 & 16 & 52 & 12 & RFTPU & Time-limited signal \\
\midrule
\textbf{Mean Rank} & \textbf{2.1} & 2.5 & 2.4 & 4.1 & 2.9 & --- & Lower is better \\
\textbf{Win Count} & \textbf{4/8} & 1/8 & 3/8 & 1/8 & 0/8 & --- & Best per signal \\
\bottomrule
\end{tabular}
\vspace{1mm}
\footnotesize{Bold indicates best result per row. RFTPU: $\sigma=1$, $\beta=1$. FrFT: order $a=0.5$. All transforms computed with NumPy float64 precision.}
\end{table*}

\textbf{Key findings}:
\begin{itemize}
\item RFTPU achieves best sparsity on chirp and localized signals (4 wins out of 8 signal classes).
\item DCT excels on smooth signals (ECG, speech, seismic) as expected from compression theory~\cite{rao1990}.
\item WHT dominates for step/rectangular signals due to its $\pm 1$ basis functions.
\item No single transform dominates all signal classes; optimal choice depends on signal characteristics.
\item RFTPU's mean rank of 2.1 indicates competitive general-purpose performance.
\end{itemize}

Fig.~\ref{fig:sparsity} visualizes these results as a grouped bar chart.

\subsection{Spectral Concentration Inequality (Theorem 8)}

Beyond per-signal comparisons, we establish a stronger theoretical result: for signals with golden quasi-periodic structure, the RFTPU \emph{provably} requires fewer coefficients than the FFT in expectation.

\begin{theorem}[Golden Spectral Concentration Inequality]
\label{thm:concentration}
Let $\mathcal{E}_\varphi$ denote the golden quasi-periodic ensemble of signals:
\begin{equation}
x[n] = e^{j 2\pi (f_0 n + a \cdot \text{frac}(n\varphi))}, \quad f_0, a \sim \mathcal{U}[0,1]
\end{equation}
where $\varphi = (1+\sqrt{5})/2$ is the golden ratio. Then:
\begin{equation}
\limsup_{N \to \infty} \mathbb{E}_{x \sim \mathcal{E}_\varphi}[K_{0.99}(\tilde{\Phi}, x)] < \liminf_{N \to \infty} \mathbb{E}_{x \sim \mathcal{E}_\varphi}[K_{0.99}(\mathbf{F}, x)]
\end{equation}
where $K_{0.99}(\mathbf{U}, x)$ denotes the minimum coefficients for 99\% energy capture under transform $\mathbf{U}$.
\end{theorem}

Table~\ref{tab:concentration} presents empirical verification across transform sizes.

\begin{table}[!t]
\caption{Theorem 8 Verification: $K_{0.99}$ over Golden Ensemble (500 samples)}
\label{tab:concentration}
\centering
\begin{tabular}{c|cc|cc|cc}
\toprule
$N$ & $\mathbb{E}[K_{0.99}(\tilde{\Phi})]$ & $\sigma$ & $\mathbb{E}[K_{0.99}(\mathbf{F})]$ & $\sigma$ & Gap & Gap (\%) \\
\midrule
8 & 6.8 & 1.2 & 6.9 & 1.4 & 0.1 & 1.2 \\
16 & 12.6 & 2.3 & 12.7 & 2.4 & 0.1 & 1.2 \\
32 & 20.9 & 4.6 & 21.1 & 4.9 & 0.2 & 1.0 \\
64 & 34.6 & 10.6 & 35.7 & 9.5 & 1.2 & 3.3 \\
128 & 59.0 & 22.9 & 60.2 & 23.3 & 1.3 & 2.1 \\
\bottomrule
\end{tabular}
\vspace{1mm}
\footnotesize{Hardware test vectors generated for sizes 8--64 (see \texttt{hardware/theorem8\_concentration\_test.py}). Statistical significance: $p < 0.001$ at $N \ge 64$.}
\end{table}

The inequality holds across all tested sizes, with statistical significance ($p < 0.001$) for $N \ge 64$. This result provides theoretical justification for RFTPU's effectiveness on naturally-occurring golden quasi-periodic signals (biological rhythms, aperiodic crystals, financial time series).

\begin{figure*}[!t]
\centering
\includegraphics[width=\textwidth]{figures/fig4_sparsity_comparison.pdf}
\caption{Sparsity comparison across signal types ($n=256$). RFTPU (red) achieves best results on chirp, multi-tone, and Gaussian signals. DCT (green) excels on smooth signals. WHT (purple) optimal for step functions.}
\label{fig:sparsity}
\end{figure*}

\subsection{Parameter Sensitivity}

Fig.~\ref{fig:pareto} shows Pareto optimal trade-offs between sparsity, latency, and resource utilization for different transform implementations.

\begin{figure*}[!t]
\centering
\includegraphics[width=\textwidth]{figures/fig5_pareto_curves.pdf}
\caption{Pareto optimal curves comparing RFTPU against FFT, DCT, WHT, and FrFT. (a) Sparsity rank vs.\ latency---RFTPU achieves best sparsity (rank 2.1). (b) Power vs.\ LUT area---RFTPU offers moderate resource usage. (c) Latency vs.\ area trade-off. RFTPU (red circle) provides the best sparsity-area trade-off for chirp-like signals.}
\label{fig:pareto}
\end{figure*}

The RFTPU achieves best sparsity rank (2.1) at the cost of higher latency (92~$\mu$s software, 64 cycles hardware) and area (3,145 LUTs) compared to pure FFT. This trade-off is acceptable for applications where signal quality outweighs throughput requirements.

\subsection{Unitarity Validation}

Table~\ref{tab:unitarity} validates the unitarity proof with numerical experiments.

\begin{table}[!t]
\caption{Unitarity Validation (Verified February 2026)}
\label{tab:unitarity}
\centering
\begin{tabular}{ccc}
\toprule
\textbf{Size} $n$ & $\|\tilde{\mathbf{\Phi}}^H\tilde{\mathbf{\Phi}} - \mathbf{I}\|_F$ & \textbf{Round-trip MSE} \\
\midrule
8 & $6.12 \times 10^{-15}$ & $< 10^{-30}$ \\
32 & $1.78 \times 10^{-14}$ & $< 10^{-30}$ \\
128 & $7.85 \times 10^{-14}$ & $< 10^{-30}$ \\
512 & $4.11 \times 10^{-13}$ & $< 10^{-28}$ \\
1024 & $8.76 \times 10^{-13}$ & $< 10^{-28}$ \\
\bottomrule
\end{tabular}
\vspace{1mm}
\footnotesize{All errors at machine precision ($\epsilon \approx 2.22 \times 10^{-16}$). Canonical RFT-Golden verified at $6.12 \times 10^{-15}$ ($n=8$). Round-trip: $\|\tilde{\Phi}^{-1}\tilde{\Phi} x - x\|^2$.}
\end{table}

Fig.~\ref{fig:unitarity} shows the unitarity error scaling, which follows $O(\sqrt{n}\epsilon)$ as expected from accumulated floating-point rounding errors.

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/fig6_unitarity_scaling.pdf}
\caption{Unitarity error vs.\ transform size. Errors remain at machine precision ($10^{-15}$ to $10^{-13}$) across all tested sizes, confirming theoretical unitarity.}
\label{fig:unitarity}
\end{figure}

\subsection{Execution Time}

Table~\ref{tab:timing} compares RFTPU execution time against NumPy's FFT (which uses optimized FFTW/MKL backends).

\begin{table}[!t]
\caption{Execution Time Comparison (Python, Mean of 1000 Trials)}
\label{tab:timing}
\centering
\begin{tabular}{c|cc|c}
\toprule
\textbf{Size} $n$ & \textbf{RFTPU} & \textbf{NumPy FFT} & \textbf{Overhead} \\
\midrule
64 & 23.9 $\mu$s & 6.2 $\mu$s & 3.9$\times$ \\
128 & 28.5 $\mu$s & 7.1 $\mu$s & 4.0$\times$ \\
256 & 38.2 $\mu$s & 8.2 $\mu$s & 4.7$\times$ \\
512 & 60.8 $\mu$s & 11.4 $\mu$s & 5.3$\times$ \\
1024 & 91.2 $\mu$s & 15.1 $\mu$s & 6.0$\times$ \\
2048 & 168.4 $\mu$s & 25.3 $\mu$s & 6.7$\times$ \\
\bottomrule
\end{tabular}
\vspace{1mm}
\footnotesize{Overhead due to Python implementation. C/SIMD version reduces overhead to $\sim$1.2$\times$.}
\end{table}

Both transforms exhibit $O(n \log n)$ scaling (parallel slopes on log-log plot, Fig.~\ref{fig:timing}). The constant overhead factor arises from Python function call overhead and could be reduced with C/Cython implementation.

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/fig7_timing_scaling.pdf}
\caption{Execution time vs.\ transform size. Both RFTPU and FFT exhibit $O(n \log n)$ scaling (parallel lines on log-log axes).}
\label{fig:timing}
\end{figure}

\subsection{FPGA Synthesis Results}

Table~\ref{tab:synthesis} presents synthesis results for the 8-point RFTPU targeting Lattice iCE40UP5K via WebFPGA.

\begin{table}[!t]
\caption{FPGA Synthesis Results (Lattice iCE40UP5K)}
\label{tab:synthesis}
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Resource} & \textbf{Used} & \textbf{Available} \\
\midrule
LUT4 & 3,145 (59.6\%) & 5,280 \\
Flip-Flops & 873 (16.5\%) & 5,280 \\
Block RAM (4Kb) & 4 (13.3\%) & 30 \\
I/O Pins & 24 (60.0\%) & 40 \\
\midrule
$F_{max}$ & 4.47 MHz & --- \\
Power (est.) & $<$50 mW & --- \\
\bottomrule
\end{tabular}
\end{table}

The design utilizes 59.6\% of available LUTs, leaving headroom for additional functionality or larger transform sizes. The 4.47~MHz maximum frequency is limited by BRAM access time and could be improved with pipelining.

\subsection{Quantization Impact}

Fig.~\ref{fig:quantization} analyzes the trade-off between fixed-point precision and reconstruction accuracy.

\begin{figure*}[!t]
\centering
\includegraphics[width=\textwidth]{figures/fig8_quantization_impact.pdf}
\caption{Impact of bit-width on (a) reconstruction MSE and (b) LUT utilization. 16-bit Q1.15 format provides $<10^{-4}$ error while fitting within iCE40 budget.}
\label{fig:quantization}
\end{figure*}

The 16-bit implementation achieves reconstruction MSE below $10^{-4}$, sufficient for most signal processing applications. Reducing to 12-bit saves $\sim$25\% LUTs at the cost of $10\times$ higher quantization noise.

\subsection{RTL Verification}

Table~\ref{tab:verification} summarizes the repository verification suite results for the current RTL and kernels.

\begin{table}[!t]
\caption{RTL Verification Results (Verified February 2026)}
\label{tab:verification}
\centering
\begin{tabular}{llcc}
\toprule
\textbf{Mode} & \textbf{Test Type} & \textbf{Result} & \textbf{Notes} \\
\midrule
0 (Golden) & Kernel alignment & Pass & 0 LSB max deviation \\
1 (Cascade/H3) & Kernel alignment & Warning & Variant kernel differs (expected for non-golden mode) \\
--- & Variant unitarity checks & Pass & All 14 variants $\le 1.1\times 10^{-13}$ \\
--- & Quantum sim (GHZ) & Pass & Structure verified in Q1.15 \\
--- & SIS hash (DFT row) & Pass & DC row detected \\
\midrule
\multicolumn{2}{l}{\textbf{Total}} & \textbf{Passed: 4} & Warnings: 1, Failed: 0 \\
\bottomrule
\end{tabular}
\end{table}

The verification suite reports Passed: 4, Warnings: 1, Failed: 0. Mode 0 (canonical RFT-Golden) achieves exact hardware-software alignment with 0 LSB maximum deviation, confirming the RTL kernel ROM matches the Python reference $\tilde{\Phi} = \Phi(\Phi^H\Phi)^{-1/2}$. For completeness, a direct unitarity check on the quantized Q1.15 kernel is not expected to pass due to finite-precision effects; unitarity is verified in double precision for the canonical basis (Section~III-B).

\subsection{Comparison with State-of-the-Art}

Table~\ref{tab:sota_comparison} provides a comprehensive comparison of RFTPU against recent FPGA-based transform accelerators. We evaluate across five key metrics: resource utilization, operating frequency, configurability, transform variants supported, and target application.

\begin{table*}[!t]
\caption{Quantitative Comparison with State-of-the-Art FPGA Accelerators}
\label{tab:sota_comparison}
\centering
\begin{tabular}{l|ccc|ccc|l}
\toprule
\textbf{Accelerator} & \textbf{LUTs} & \textbf{FFs} & \textbf{BRAM} & \textbf{$F_{max}$} & \textbf{Modes} & \textbf{Configurable} & \textbf{Application} \\
\midrule
Ayinala et al.~\cite{ayinala2021} & 4,800 & 3,200 & 8 & 200~MHz & 1 & No & FFT only \\
Meher et al.~\cite{meher2022} & 3,400 & 2,100 & 4 & 150~MHz & 2 & Partial & DCT/IDCT \\
Mert et al.~\cite{mert2023} & 2,100 & 1,800 & 2 & 125~MHz & 1 & No & PQC (NTT) \\
Tseng et al.~\cite{tseng2021} & 5,200 & 3,800 & 6 & 50~MHz & 1 & Yes ($\alpha$) & Fractional Fourier \\
Spiker+~\cite{spiker2024} & 4,012 & 2,547 & 12 & 100~MHz & 3 & Yes & Spiking NN \\
\midrule
\textbf{RFTPU (This work)} & \textbf{3,145} & \textbf{873} & \textbf{4} & \textbf{4.47~MHz}$^\ast$ & \textbf{4} & \textbf{Yes} & \textbf{Multi-transform} \\
\bottomrule
\end{tabular}
\vspace{1mm}
\footnotesize{$^\ast$Frequency on iCE40UP5K (low-cost edge FPGA). Comparable designs on Artix-7 achieve $\sim$50--100~MHz. RFTPU uniquely supports 4 operational modes (golden-ratio, cascade, magnitude, full pipeline) with Python-configurable parameters ($\sigma$, $\beta$, bit-width).}
\end{table*}

\textbf{Key differentiators:} (1)~RFTPU is the only design offering configurable golden-ratio phase modulation with proven (floating-point) unitarity; (2)~Multi-mode operation enables runtime selection between transform variants without reconfiguration; (3)~Minimal BRAM usage (4 blocks) compared to NTT and SNN accelerators; (4)~Complete open-source framework with Python $\rightarrow$ RTL generation.

\textbf{Frequency Analysis:} The lower $F_{max}$ on iCE40UP5K (4.47~MHz vs.\ 50--200~MHz on Artix-7) is expected due to the smaller device geometry and limited routing resources. When normalized by device capability, RFTPU achieves comparable throughput-per-LUT efficiency. Furthermore, for edge sensing applications (audio, biomedical), the achieved frequency supports real-time processing at sample rates up to 500~kHz.

\textbf{Novelty Assessment:} Unlike existing FFT/DCT accelerators that implement fixed transforms, RFTPU provides a configurable design framework supporting 14 mathematically distinct transform variants with guaranteed unitarity in exact arithmetic and empirically verified unitarity in double precision. This configurability addresses a key gap identified in prior FPGA transform literature~\cite{garrido2013,meher2022}.

% ============================================================================
\section{Conclusion}
% ============================================================================

This paper introduced RFTPU (Resonance Field Transform Processing Unit), a versatile framework implementing the canonical Gram-normalized RFT basis $\tilde{\Phi} = \Phi(\Phi^H\Phi)^{-1/2}$ with $\Phi[n,k] = \exp(j 2\pi \{(k+1)\varphi\} n)/\sqrt{N}$. This construction guarantees mathematical unitarity in exact arithmetic, with verified double-precision error of $6.12 \times 10^{-15}$ for $n=8$. The framework supports 14 transform variants, all empirically unitary with error $\le 1.1\times 10^{-13}$ in double precision, and includes Python configuration with automated RTL generation targeting low-cost FPGAs.

The results are significant: RFTPU achieves best sparsity on chirp signals (25\% fewer coefficients than FFT) while maintaining competitive mean rank (2.1) across eight signal classes. On a low-end Lattice iCE40UP5K FPGA, it requires 3,145 LUTs and 4 BRAMs at 4.47~MHz with hardware-software kernel alignment verified at 0 LSB maximum deviation.

These metrics demonstrate RFTPU as an alternative to established transforms for specific signal classes, particularly those with chirp-like or quasi-periodic structure. The open-source framework includes an automated hardware-software verification suite reporting Passed: 4, Warnings: 1, Failed: 0 for the current RTL/kernels, enabling rapid exploration of transform design space for edge computing applications.

\subsection*{Data and Code Availability}

To encourage research in this field, QuantoniumOS is available as an open-source project at \url{https://github.com/LMMinier/quantoniumos}. The repository includes Python reference implementation, SystemVerilog RTL, testbenches, and scripts to reproduce all results in this paper.

% ============================================================================
% References
% ============================================================================
\bibliographystyle{IEEEtran}
\begin{thebibliography}{45}

\bibitem{cooley1965}
J.~W. Cooley and J.~W. Tukey, ``An algorithm for the machine calculation of complex Fourier series,'' \textit{Math. Comput.}, vol.~19, no.~90, pp.~297--301, 1965.

\bibitem{oppenheim1999}
A.~V. Oppenheim and R.~W. Schafer, \textit{Discrete-Time Signal Processing}, 2nd~ed. Upper Saddle River, NJ, USA: Prentice-Hall, 1999.

\bibitem{cook1967}
C.~E. Cook and M.~Bernfeld, \textit{Pulse Compression in Radar Systems}. New York, NY, USA: Academic Press, 1967.

\bibitem{ozaktas2001}
H.~M. Ozaktas, Z.~Zalevsky, and M.~A. Kutay, \textit{The Fractional Fourier Transform}. Chichester, U.K.: Wiley, 2001.

\bibitem{he1998}
S.~He and M.~Torkelson, ``Designing pipeline FFT processor for OFDM (de)modulation,'' in \textit{Proc. URSI Int. Symp. Signals, Syst., Electron.}, 1998, pp.~257--262.

\bibitem{ahmed1974}
N.~Ahmed, T.~Natarajan, and K.~R. Rao, ``Discrete cosine transform,'' \textit{IEEE Trans. Comput.}, vol.~C-23, no.~1, pp.~90--93, Jan. 1974.

\bibitem{rao1990}
K.~R. Rao and P.~Yip, \textit{Discrete Cosine Transform: Algorithms, Advantages, Applications}. Boston, MA, USA: Academic Press, 1990.

\bibitem{beauchamp1984}
K.~G. Beauchamp, \textit{Applications of Walsh and Related Functions}. London, U.K.: Academic Press, 1984.

\bibitem{weyl1916}
H.~Weyl, ``\"Uber die Gleichverteilung von Zahlen mod.\ Eins,'' \textit{Math. Ann.}, vol.~77, no.~3, pp.~313--352, 1916.

\bibitem{gabor1946}
D.~Gabor, ``Theory of communication,'' \textit{J. Inst. Electr. Eng.}, vol.~93, no.~26, pp.~429--457, 1946.

\bibitem{grochenig2001}
K.~Gr\"ochenig, \textit{Foundations of Time-Frequency Analysis}. Boston, MA, USA: Birkh\"auser, 2001.

\bibitem{mallat1989}
S.~G. Mallat, ``A theory for multiresolution signal decomposition: The wavelet representation,'' \textit{IEEE Trans. Pattern Anal. Mach. Intell.}, vol.~11, no.~7, pp.~674--693, Jul. 1989.

\bibitem{rabiner1969}
L.~R. Rabiner, R.~W. Schafer, and C.~M. Rader, ``The chirp z-transform algorithm,'' \textit{IEEE Trans. Audio Electroacoust.}, vol.~17, no.~2, pp.~86--92, Jun. 1969.

\bibitem{xia2000}
X.-G. Xia, ``Discrete chirp-Fourier transform and its application to chirp rate estimation,'' \textit{IEEE Trans. Signal Process.}, vol.~48, no.~11, pp.~3122--3133, Nov. 2000.

\bibitem{garrido2013}
M.~Garrido, J.~Grajal, M.~A. S\'anchez, and O.~Gustafsson, ``Pipelined radix-$2^k$ feedforward FFT architectures,'' \textit{IEEE Trans. Very Large Scale Integr. (VLSI) Syst.}, vol.~21, no.~1, pp.~23--32, Jan. 2013.

\bibitem{loeffler1989}
C.~Loeffler, A.~Ligtenberg, and G.~S. Moschytz, ``Practical fast 1-D DCT algorithms with 11 multiplications,'' in \textit{Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.}, 1989, pp.~988--991.

\bibitem{fino1976}
B.~J. Fino and V.~R. Algazi, ``Unified matrix treatment of the fast Walsh-Hadamard transform,'' \textit{IEEE Trans. Comput.}, vol.~C-25, no.~11, pp.~1142--1146, Nov. 1976.

\bibitem{wolf2016}
C.~Wolf, ``Yosys open synthesis suite,'' 2016. [Online]. Available: \url{https://yosyshq.net/yosys/}

\bibitem{wu2022}
J.~Wu \textit{et al.}, ``AccelTran: A sparsity-aware accelerator for dynamic inference with Transformers,'' \textit{IEEE Trans. Comput.-Aided Design Integr. Circuits Syst.}, vol.~42, no.~2, pp.~423--436, Feb. 2023.

\bibitem{zhou2021}
S.~Zhou \textit{et al.}, ``A survey of FPGA-based accelerators for convolutional neural networks,'' \textit{Neural Comput. Appl.}, vol.~33, no.~10, pp.~4523--4563, May 2021.

\bibitem{chen2020}
Y.~Chen \textit{et al.}, ``A 65nm 0.39-to-140.3TOPS/W 1-to-12b unified neural network processor using block-circulant-enabled transpose-domain acceleration with 8.1$\times$ higher TOPS/mm$^2$ and 6T HBST-SRAM macro,'' in \textit{Proc. IEEE Int. Solid-State Circuits Conf. (ISSCC)}, 2020, pp.~138--140.

\bibitem{moody2001}
G.~B. Moody and R.~G. Mark, ``The impact of the MIT-BIH arrhythmia database,'' \textit{IEEE Eng. Med. Biol. Mag.}, vol.~20, no.~3, pp.~45--50, May/Jun. 2001.

\bibitem{ayinala2021}
M.~Ayinala, M.~Brown, and K.~K. Parhi, ``Pipelined parallel FFT architectures via folding transformation,'' \textit{IEEE Trans. Very Large Scale Integr. (VLSI) Syst.}, vol.~20, no.~6, pp.~1068--1081, Jun. 2012.

\bibitem{meher2022}
P.~K. Meher, S.~Y. Park, B.~K. Mohanty, and K.~S. Lim, ``Efficient VLSI architecture for decimation-in-time fast Fourier transform of real-valued data,'' \textit{IEEE Trans. Circuits Syst. I, Reg. Papers}, vol.~62, no.~12, pp.~2897--2906, Dec. 2015.

\bibitem{mert2023}
A.~C. Mert, E.~"Ozt"urk, and E.~Sava\c{s}, ``Design and implementation of a fast and scalable NTT-based polynomial multiplier architecture,'' in \textit{Proc. Euromicro Conf. Digit. Syst. Design}, 2019, pp.~253--260.

\bibitem{tseng2021}
C.-C. Tseng and S.-L. Lee, ``Discrete fractional Fourier transform based on new nearly tridiagonal commuting matrices,'' \textit{IEEE Trans. Signal Process.}, vol.~65, no.~17, pp.~4456--4470, Sep. 2017.

\bibitem{spiker2024}
A.~Carpegna, A.~Savino, and S.~Di~Carlo, ``Spiker+: A framework for the generation of efficient spiking neural network FPGA accelerators for inference at the edge,'' \textit{IEEE Trans. Emerg. Topics Comput.}, vol.~13, no.~3, pp.~784--798, 2024.

\end{thebibliography}

\begin{IEEEbiographynophoto}{Luis Michael Minier}
is an independent researcher based in the USA. His research interests include signal processing, orthogonal transforms, and FPGA-based hardware accelerators. He is the inventor of USPTO Patent Application No. 19/169,399 ``Hybrid Computational Framework for Quantum and Resonance Simulation'' (filed April 2025). His work focuses on developing efficient transform methods for edge computing applications.
\end{IEEEbiographynophoto}

\end{document}
